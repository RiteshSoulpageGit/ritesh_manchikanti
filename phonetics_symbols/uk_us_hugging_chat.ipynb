{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from hugchat import hugchat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugchat import hugchat\n",
    "\n",
    "def chat_with_bot(text):\n",
    "    \n",
    "    chatbot = hugchat.ChatBot(cookie_path=\"/home/ubuntu/cookies.json\")\n",
    "    try:\n",
    "        response = chatbot.chat(text,temperature=0.2,\n",
    "                                top_k=95,\n",
    "                                max_new_tokens=512,\n",
    "                                )\n",
    "    except:\n",
    "        response = \"0\"\n",
    "    #print(text)\n",
    "    # Create a new conversation\n",
    "    \n",
    "    id = chatbot.new_conversation()\n",
    "    chatbot.change_conversation(id)\n",
    "    \n",
    "\n",
    "    # Get conversation list \n",
    "    conversation_list = chatbot.get_conversation_list()\n",
    "\n",
    "    return conversation_list, response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(desired_files_df, max_sentence_length):\n",
    "    for idx in range(desired_files_df.shape[0]):\n",
    "        x = desired_files_df[\"text\"].iloc[idx]\n",
    "        # print(\"##\",x)\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', x)\n",
    "        # print(\"**sentences:\",sentences)\n",
    "        print(len(sentences))\n",
    "        # break\n",
    "        # Adjust the maximum sentence length as per your requirements\n",
    "\n",
    "        chunks = sentences\n",
    "\n",
    "        final_chunks = []\n",
    "        new_data = \"\"\n",
    "        index = 0\n",
    "        index1 = -1\n",
    "\n",
    "        for c_index,sentence in enumerate(chunks[index:index1]):\n",
    "            # print(\"each sentence lenght:\", len(sentence.split(\" \")))\n",
    "            if len(sentence.split(\" \")) <= max_sentence_length and len((new_data+sentence).split(\" \"))<= max_sentence_length:\n",
    "                new_data = new_data+sentence\n",
    "            else:\n",
    "                # print(\"next setence lenght:\", index, len(sentence.split(\" \")))\n",
    "                final_chunks.append(new_data)\n",
    "                new_data = \"\"\n",
    "                index = c_index\n",
    "    return final_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/cat_poc/llms/final_data.csv\"\n",
    "data_frame = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15031-4983-FullBook.docx</td>\n",
       "      <td>Learner Choice, Learning Voice\\n\\n\\nLearner Vo...</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15031-4984-FullBook.docx</td>\n",
       "      <td>\\n\\nExistentialism: A Philosophical Inquiry\\n\\...</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15031-4985-FullBook.docx</td>\n",
       "      <td>\"The editors of this volume are the top practi...</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15031-4986-FullBook.docx</td>\n",
       "      <td>Black Power Music!\\n\\nBlack Power Music!: Prot...</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15031-4989-FullBook.docx</td>\n",
       "      <td>Home\\n\\n\\nHome articulates a ‘critical geograp...</td>\n",
       "      <td>Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>15032-5774-FullBook.docx</td>\n",
       "      <td>The Japanese LGBTQ+ Community in the World\\n\\n...</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>15032-5789-FullBook.docx</td>\n",
       "      <td>The Acquisition of English Grammar and Phonolo...</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>15032-5829-FullBook.docx</td>\n",
       "      <td>\\n‘New concepts, new words for them, new actio...</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>15032-5843-FullBook.docx</td>\n",
       "      <td>Translating Rumi into the West\\n\\n\\nFocusing o...</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>15032-6039-FullBook.docx</td>\n",
       "      <td>Reassessing Vocational Education in China\\n\\nB...</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1236 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  \\\n",
       "0     15031-4983-FullBook.docx   \n",
       "1     15031-4984-FullBook.docx   \n",
       "2     15031-4985-FullBook.docx   \n",
       "3     15031-4986-FullBook.docx   \n",
       "4     15031-4989-FullBook.docx   \n",
       "...                        ...   \n",
       "1231  15032-5774-FullBook.docx   \n",
       "1232  15032-5789-FullBook.docx   \n",
       "1233  15032-5829-FullBook.docx   \n",
       "1234  15032-5843-FullBook.docx   \n",
       "1235  15032-6039-FullBook.docx   \n",
       "\n",
       "                                                   text    level  \n",
       "0     Learner Choice, Learning Voice\\n\\n\\nLearner Vo...  Level 1  \n",
       "1     \\n\\nExistentialism: A Philosophical Inquiry\\n\\...  Level 1  \n",
       "2     \"The editors of this volume are the top practi...  Level 1  \n",
       "3     Black Power Music!\\n\\nBlack Power Music!: Prot...  Level 1  \n",
       "4     Home\\n\\n\\nHome articulates a ‘critical geograp...  Level 1  \n",
       "...                                                 ...      ...  \n",
       "1231  The Japanese LGBTQ+ Community in the World\\n\\n...  Level 3  \n",
       "1232  The Acquisition of English Grammar and Phonolo...  Level 3  \n",
       "1233  \\n‘New concepts, new words for them, new actio...  Level 3  \n",
       "1234  Translating Rumi into the West\\n\\n\\nFocusing o...  Level 3  \n",
       "1235  Reassessing Vocational Education in China\\n\\nB...  Level 3  \n",
       "\n",
       "[1236 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_frame[data_frame[\"filename\"] == \"15031-4983-FullBook.docx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3256\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 400  # Adjust the chunk size as per your requirements\n",
    "\n",
    "chunks_data = read_files(data, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 ['But', 'beyond', 'that,', 'the', 'book', 'acts', 'as', 'a', 'catalyst', 'for', 'inspiration', 'that', 'helps', 'educators', 'reimagine', 'what', 'education', 'can', 'be', 'in', 'a', 'time', 'of', 'global', 'transformation', '-', 'because', 'not', 'only', 'has', 'the', 'world', 'changed', 'but', 'so', 'has', 'education.Enjoy!!!Dr.Nicky', 'Mohan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction\\nThe', 'Need', 'for', 'Teacher', 'and', 'Learner', 'Agency', 'In', 'Pandemic', 'Times\\n\\nThe', 'global', 'pandemic', 'has', 'had', 'a', 'profound', 'effect', 'on', 'traditional', 'learning', 'processes.Remote', 'learning', 'has', 'created', 'opportunities', 'for', 'learners', 'to', 'turn', 'down', 'the', 'volume', 'on', 'their', 'teachers', 'or', 'even', 'turn', 'them', 'off', 'completely.This', 'ability', 'to', 'tune', 'out', 'is', 'transforming', 'many', 'of', 'our', 'traditional', 'assumptions', 'about', 'teaching', 'and', 'learning.Even', 'if', 'conventional', 'compliance-focused', 'approaches', 'may', 'have', 'previously', 'worked', 'in', 'engaging', 'learners,', 'these', 'same', 'techniques', 'increasingly', 'won’t', 'be', 'as', 'effective', '--', 'particularly', 'in', 'a', 'time', 'where', 'we', 'will', 'almost', 'certainly', 'continue', 'to', 'experience', 'accelerated', 'rates', 'of', 'disruptive', 'change', 'in', 'our', 'world', '-', 'change', 'caused,', 'in', 'large', 'part,', 'by', 'the', 'pandemic.The', 'short', 'and', 'long-term', 'implications', 'of', 'this', 'emerging', 'reality', 'are', 'substantial.They', 'require', 'educators', 'to', 'reassess', 'our', 'relationship', 'with', 'learners', 'carefully', 'and', 'fundamentally', 'rethink', 'how', 'we', 'approach', 'teaching,', 'learning,', 'and', 'assessment', 'in', 'the', 'modern', 'world.Amid', 'pandemic', 'times,', 'educators', 'and', 'educational', 'leaders', 'struggle', 'with', 'a', 'wide', 'range', 'of', 'technical', 'and', 'adaptive', 'challenges.While', 'many', 'of', 'these', 'problems', 'are', 'technical,', 'overwhelmingly,', 'the', 'most', 'significant', 'challenges', 'are', 'adaptive.Moreover,', 'adaptive', 'challenges', 'reflect', 'issues', 'for', 'which', 'there', 'are', 'no', 'quickly', 'discernible', 'answers.Thus,', 'adaptive', 'challenges', 'cannot', 'be', 'instantly', 'solved', 'by', 'external', 'experts.Nor', 'can', 'solutions', 'be', 'implemented', 'by', 'mandate.Instead,', 'solving', 'adaptive', 'challenges', 'requires', 'experimentation', 'by', 'those', 'directly', 'experiencing', 'the', 'problem.In', 'earlier', 'times,', 'most', 'of', 'the', 'challenges', 'educators', 'faced', 'were', 'technical,', 'and', 'the', 'nature', 'of', 'work', 'primarily', 'required', 'teachers', 'to', 'conform', 'to', 'long-established', 'practices,', 'routines,', 'and', 'protocols.This', 'approach', 'was', 'the', 'foundation', 'of', 'the', 'process-based,', 'factory', 'mindset', 'design', 'exhibited', 'by', 'the', 'traditional', 'education', 'system.However,', 'even', 'before', 'the', 'appearance', 'of', 'COVID-19,', 'there', 'had', 'been', 'a', 'dramatic', 'shift', 'to', 'a', 'post-industrial,', 'global', 'digital', 'world', 'and', 'economy,', 'which', 'led', 'to', 'additional', 'changes', 'to', 'long-held', 'values,', 'expectations,', 'and', 'assumptions.As', 'a', 'result,', 'we', 'often', 'sought', 'technical', 'solutions', 'to', 'solve', 'adaptive', 'challenges', 'in', 'our', 'schools', '-', 'something', 'COVID-19', 'has', 'further', 'accelerated.Moving', 'forward', '(hopefully)', 'post-pandemic,', 'the', 'primary', 'challenges', 'facing', 'educators', 'will', 'be', 'more', 'adaptive', 'than', 'technical.With', 'today’s', 'COVID', 'learners,', 'we', 'are', 'increasingly', 'facing', 'drop-out,', 'tune-out', 'issues.In', 'a', 'world', 'full', 'of', 'accelerating', 'levels', 'of', 'distraction', 'and', 'choice,', 'there', 'are', 'any', 'number', 'of', 'alternatives', 'to', 'engaging', 'in', 'school', '-', 'many', 'of', 'which', 'have', 'been', 'further', 'amplified', 'by', 'the', 'effects', 'of', 'the', 'pandemic.']\n"
     ]
    }
   ],
   "source": [
    "x = chunks_data[5]\n",
    "print(len(x.split(\" \")),x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt_beginners = [\n",
    "    # ''' Analyse  the following text  weather it has number_treatment give me respose in \"Yes\" or \"No\" only'''\n",
    "    ''' count no of phonetics, symbols that are there in the doccument and give me the count number '''\n",
    "    # '''Analyse  the following text  weather it has Single_or_double_quotes and give me respose in \"Single\" or \"double\" only?:''',\n",
    "    # '''Analyse  the following text  weather it has Series_comma and give me respose in \"Yes\" or \"No\" only?:''',\n",
    "    # '''analyse  the below text  weather it is in \"American_english style\" or \"British english style and give me respose in \"American\" or \"British\" only?:\"'''\n",
    "]\n",
    "\n",
    "Modified_chunks = []\n",
    "for prompt in prompt_beginners:\n",
    "    prompt_line = f'''{prompt}'''\n",
    "    for chunk_i in chunks_data[:10]:\n",
    "        input_text = prompt_line + chunk_i\n",
    "        Modified_chunks.append(input_text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Modified_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' count no of phonetics, symbols are there in the doccument and give me the count number Library of Congress Cataloging-in-Publication Data\\nA catalog record for this title has been requested\\n\\nISBN: 9780367567910 (hbk)\\nISBN: 9780367610340 (pbk)\\nISBN: 9781003102984 (ebk)\\n\\nDOI: 10.4324/9781003102984\\n\\nTypeset in Palatino \\nby [Typesetter]\\n\\n\\nDedications\\n\\nI want to dedicate this book to my family.Rachel, Connor, and Ben, you are my life.To my wonderful mother, Susan, and my sister, Kristy, - thank you for the love and support.I also would like to thank the faculty, staff, and students at both Notre Dame of Maryland University and Johns Hopkins University for allowing me to fulfill my passion for teaching the teachers of today and tomorrow.-Ryan L.Schaaf\\n\\nI want to dedicate this book to my parents, who always promoted the value of a strong education.From installing my pretend classroom in our basement and pretending to be my first students, to encouraging me throughout college and graduate school, I am forever grateful.To my husband, Nick, thank you for being my first editor and always allowing me to bounce ideas off of you.We are a team.Thank you for always supporting me.Ian and Ryan, thank you for this unbelievable opportunity and all that you have taught me throughout this experience.-Becky Zayas\\n\\nThis book is intended to celebrate the exceptional dedication and courage educators have exhibited, and to acknowledge their demonstrated capacity to adapt and innovate in extraordinarily challenging and uncertain conditions.Now is the time for us to recognize the exceptional role they play, and to empower them with the training, professional development, support, and working conditions needed to effectively deploy their talents.For the education system to recover from the COVID pandemic requires sustained investment in the well-being, training, professional development and working conditions of the world’s 71 million educators.Education recovery will only be successful if it is conducted hand-in-hand with teachers, giving them both voice and agency to participate in the critical change process.- Ian Jukes\\n\\n\\n\\n\\nContents\\n\\nMeet the Authors\\n\\nForeword: Dr.Nicky Mohan, InfoSavvy 21\\n\\nIntroduction: The Need for Teacher and Learner Agency In Pandemic Times \\nStorytime \\nA Starting Point \\nChapter 1: What is Learner Agency?Chapter 2: The Empowerers of Empowerment \\n\\nChapter 3: The Digital Generations and the Great Disconnect \\n\\nChapter 4: Rise of the Creative Class \\n\\nChapter 5: Modern Learners, Modern Skills \\n\\nChapter 6: THE LIST \\n\\nChapter 7: Authentic Assessment for Authentic Learning \\n\\nChapter 8: The Best of Both Worlds: Providing Learner Empowerment in the Age of High-Stakes Learning\\n\\n\\nMeet the Authors\\n[Insert 15031-4983-0FM-Figure-001 Here]\\nRyan L.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Modified_chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = Modified_chunks[2]\n",
    "# print(len(x.split(\" \")),x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation List: ['648ffe58a4b17db3cc6b83fb', '648ffe65bdb2191d2c0a979f']\n",
      "Response: There are approximately 30 phonetic symbols in the document. These include letters with diacritic marks, such as á, é, í, ó, ú, ü, ñ, and accented vowels like à, è, ì, ò, ù, û, ï. Additionally, there are symbols representing Greek letters, such as α, β, γ, δ, ε, ζ, η, θ, ι, κ, λ, μ, ν, ξ, ο, π, ρ, σ, τ, υ, φ, χ, ψ, ω. Finally, there are symbols representing mathematical operators, such as +, -, ×, ÷, =, <, >, (, ), ^, _, etc.\n",
      "\n",
      "Conversation List: ['648ffe6c4d344ab119af4319', '648ffe764571852aa49e0347']\n",
      "Response: There are 14 phonetic symbols in the given document. These include \"@\" symbol used as part of email addresses, \"#\" symbol used in chapter titles, \"%\" symbol used in URLs, \"^\" symbol used in superscript text, \"&\" symbol used in names of companies, \"'\" symbol used in quotations, \"<>\" symbol used in HTML code, \"( )\" symbol used in parentheses, \"-\" symbol used in hyphenation, \":\" symbol used in times and dates, \";\" symbol used in lists, \".\" symbol used in decimal numbers, and \",\" symbol used in lists.\n",
      "\n",
      "Conversation List: ['648ffe7e4571852aa49e0348', '648ffe81724ffa15d6623c80']\n",
      "Response: There are 6 phonetic symbols in this document.\n",
      "\n",
      "Conversation List: ['648ffe89525d2d2474970944', '648ffe90a4b17db3cc6b83fd']\n",
      "Response: There are approximately 54 phonetic symbols in this document. These include letters, numbers, punctuation marks, and other characters used for formatting and layout purposes. However, if you only count the actual words and sentences, then there would be around 700-800 phonetic symbols.\n",
      "\n",
      "Conversation List: ['648ffe98724ffa15d6623c84', '648ffe9b4571852aa49e034c']\n",
      "Response: There are 26 phonetic symbols in the document.\n",
      "\n",
      "Conversation List: ['648ffea24571852aa49e034d', '648ffea44571852aa49e034e']\n",
      "Response: 20\n",
      "\n",
      "Conversation List: ['648ffeabbdb2191d2c0a97a5', '648ffeae724ffa15d6623c85']\n",
      "Response: There are 12 phonetic symbols in the given document.\n",
      "\n",
      "Conversation List: ['648ffeb5525d2d2474970947', '648ffeb7bdb2191d2c0a97a6']\n",
      "Response: There are 12 phonetic symbols in the given document.\n",
      "\n",
      "Conversation List: ['648ffebea4b17db3cc6b83fe', '648ffec14571852aa49e0350']\n",
      "Response: There are 10 phonetic symbols in the document.\n",
      "\n",
      "Conversation List: ['648ffec8bdb2191d2c0a97a7', '648ffeca56b64bb432151de0']\n",
      "Response: There are 14 phonetic symbols in the given document.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk_data in Modified_chunks[:]:\n",
    "    conversation_list, response = chat_with_bot(chunk_data)\n",
    "    print(\"Conversation List:\", conversation_list)\n",
    "    print(\"Response:\", response)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation List: ['64830461eb69948f6539b2d4', '64830463eb69948f6539b2d5']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['6483046ae77e5ce19faee9d1', '6483046d5d5e605bba2b96a8']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['64830474d1a98e52981e4f3f', '64830476eb69948f6539b2d9']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['6483047ca16fd6adf898ebc3', '6483047e5d5e605bba2b96ab']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['64830485a16fd6adf898ebc4', '64830487e77e5ce19faee9d5']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['6483048f5d5e605bba2b96ac', '64830490a16fd6adf898ebc6']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['648304975d5e605bba2b96b0', '64830498e77e5ce19faee9db']\n",
      "Response: single\n",
      "\n",
      "error_count: single\n",
      "Conversation List: ['648304a05d5e605bba2b96b1', '648304a2a16fd6adf898ebc7']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['648304a8f230bbb3bf1a2d9a', '648304a9f340bc57eed1b510']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['648304b1e77e5ce19faee9e6', '648304b33fab97aeba5d7ebd']\n",
      "Response: double\n",
      "\n",
      "error_count: double\n",
      "Conversation List: ['648304baf340bc57eed1b516', '648304bcf340bc57eed1b517']\n",
      "Response: Yes\n",
      "\n",
      "error_count: Yes\n",
      "Conversation List: ['648304c3e77e5ce19faee9e8', '648304c5e77e5ce19faee9e9']\n",
      "Response: Yes\n",
      "\n",
      "error_count: Yes\n",
      "Conversation List: ['648304cce77e5ce19faee9ea', '648304ce5d5e605bba2b96b4']\n",
      "Response: Yes\n",
      "\n",
      "error_count: Yes\n",
      "Conversation List: ['648304d63fab97aeba5d7ec6', '648304d75d5e605bba2b96b5']\n",
      "Response: Yes\n",
      "\n",
      "error_count: Yes\n",
      "Conversation List: ['648304def230bbb3bf1a2d9f', '648304e03fab97aeba5d7ec7']\n",
      "Response: Yes.\n",
      "\n",
      "error_count: Yes.\n",
      "Conversation List: ['648304e73fab97aeba5d7ec8', '648304e8e77e5ce19faee9ed']\n",
      "Response: Yes\n",
      "\n",
      "error_count: Yes\n",
      "Conversation List: ['648304eef340bc57eed1b51c', '648304f03fab97aeba5d7eca']\n",
      "Response: Yes\n",
      "\n",
      "error_count: Yes\n",
      "Conversation List: ['648304f7d1a98e52981e4f4f', '648304f8d1a98e52981e4f50']\n",
      "Response: Yes\n",
      "\n",
      "error_count: Yes\n",
      "Conversation List: ['648305003fab97aeba5d7ecd', '648305013fab97aeba5d7ecf']\n",
      "Response: Yes.\n",
      "\n",
      "error_count: Yes.\n",
      "Conversation List: ['64830509a16fd6adf898ebcc', '6483050a3fab97aeba5d7ed1']\n",
      "Response: Yes.\n",
      "\n",
      "error_count: Yes.\n",
      "Conversation List: ['648305113fab97aeba5d7ed2', '64830513eb69948f6539b2f1']\n",
      "Response: American English style.\n",
      "\n",
      "error_count: American English style.\n",
      "Conversation List: ['6483051aeb69948f6539b2f2', '6483051c3fab97aeba5d7ed4']\n",
      "Response: American English style.\n",
      "\n",
      "error_count: American English style.\n",
      "Conversation List: ['64830523e77e5ce19faee9f1', '64830525d1a98e52981e4f54']\n",
      "Response: American English style.\n",
      "\n",
      "error_count: American English style.\n",
      "Conversation List: ['6483052cd1a98e52981e4f56', '6483052ee77e5ce19faee9f2']\n",
      "Response: American English.\n",
      "\n",
      "error_count: American English.\n",
      "Conversation List: ['648305353fab97aeba5d7eda', '64830537f230bbb3bf1a2da2']\n",
      "Response: American English\n",
      "\n",
      "error_count: American English\n",
      "Conversation List: ['6483053ef340bc57eed1b529', '6483055ca16fd6adf898ebd3']\n",
      "Response: 0\n",
      "\n",
      "error_count: 0\n",
      "Conversation List: ['64830563f340bc57eed1b52e', '6483057ea16fd6adf898ebd9']\n",
      "Response: British English:\n",
      "\n",
      "* For some, this distraction comes in the form of the daily stress that results from poverty, constant uncertainty, and fear, which draws students’ focus away from learning.\n",
      "* For others, it’s the ever-present presence of digital technology in the form of gaming, social media, connection to peers, and constant exposure to the ever-present YouTube and TikTok culture.\n",
      "* Thus, the pandemic has simultaneously compounded the inequalities that already exist between those who have and those who do not access – while at the same time expanding the use of digital technology and increasing our dependence on digital devices and services.\n",
      "* Once we finally get beyond COVID, it is highly unlikely that schools will deny the intrusion of these powerful societal forces and the changes they are imposing upon us because neither factor is well aligned to a compliance-driven solution for education.\n",
      "* As we move forward, education will need to compete for learner attention in a time of ongoing uncertainty and instability on the one hand, and instant access to anytime, anywhere digital entertainment and learning experiences on the other.\n",
      "* Effective classroom management could, in some cases, create environments where at least outwardly, it appeared that students were relatively engaged.\n",
      "* Throughout time, both individually and collectively, educators have exerted influence over learners. But, despite the outward appearance of control manifested and often assumed in the classroom, the reality is that we are all effectively interacting with other individuals and groups who also have agency.\n",
      "* When COVID compelled traditional learning to switch to a remote or hybrid model, the digital prototype used to maintain a semblance of control and order no longer worked as effectively as the in-person model.\n",
      "\n",
      "American English:\n",
      "\n",
      "* For some, this distraction comes in the form of the daily stress that results from poverty, constant uncertainty, and fear, which draws students’ focus away from learning.\n",
      "* For others, it’s the ever-present presence of digital techno\n",
      "\n",
      "error_count: British English:\n",
      "\n",
      "* For some, this distraction comes in the form of the daily stress that results from poverty, constant uncertainty, and fear, which draws students’ focus away from learning.\n",
      "* For others, it’s the ever-present presence of digital technology in the form of gaming, social media, connection to peers, and constant exposure to the ever-present YouTube and TikTok culture.\n",
      "* Thus, the pandemic has simultaneously compounded the inequalities that already exist between those who have and those who do not access – while at the same time expanding the use of digital technology and increasing our dependence on digital devices and services.\n",
      "* Once we finally get beyond COVID, it is highly unlikely that schools will deny the intrusion of these powerful societal forces and the changes they are imposing upon us because neither factor is well aligned to a compliance-driven solution for education.\n",
      "* As we move forward, education will need to compete for learner attention in a time of ongoing uncertainty and instability on the one hand, and instant access to anytime, anywhere digital entertainment and learning experiences on the other.\n",
      "* Effective classroom management could, in some cases, create environments where at least outwardly, it appeared that students were relatively engaged.\n",
      "* Throughout time, both individually and collectively, educators have exerted influence over learners. But, despite the outward appearance of control manifested and often assumed in the classroom, the reality is that we are all effectively interacting with other individuals and groups who also have agency.\n",
      "* When COVID compelled traditional learning to switch to a remote or hybrid model, the digital prototype used to maintain a semblance of control and order no longer worked as effectively as the in-person model.\n",
      "\n",
      "American English:\n",
      "\n",
      "* For some, this distraction comes in the form of the daily stress that results from poverty, constant uncertainty, and fear, which draws students’ focus away from learning.\n",
      "* For others, it’s the ever-present presence of digital techno\n",
      "Conversation List: ['648305855d5e605bba2b96bd', '6483058ad1a98e52981e4f5c']\n",
      "Response: American English:\n",
      "The text appears to be written in American English style. Some key indicators include the spelling of words like \"center\" instead of \"centre,\" and the use of phrases like \"learners have even more reason to turn down the volume and tune us out.\" Overall, the language used is straightforward and easy to understand, which is characteristic of American English.\n",
      "\n",
      "error_count: American English:\n",
      "The text appears to be written in American English style. Some key indicators include the spelling of words like \"center\" instead of \"centre,\" and the use of phrases like \"learners have even more reason to turn down the volume and tune us out.\" Overall, the language used is straightforward and easy to understand, which is characteristic of American English.\n",
      "Conversation List: ['64830592f340bc57eed1b533', '64830598a16fd6adf898ebde']\n",
      "Response: American English:\n",
      "\n",
      "This text appears to be written in American English. Some key indicators include the use of words like \"Montessoribased,\" which is spelled differently than the British English version (\"Montessori-based\"). Additionally, phrases like \"arts-integrated charter school\" and \"state-mandated standardized tests\" are common terms used in American schools. Overall, the language and tone of the text seem to align with American English conventions.\n",
      "\n",
      "error_count: American English:\n",
      "\n",
      "This text appears to be written in American English. Some key indicators include the use of words like \"Montessoribased,\" which is spelled differently than the British English version (\"Montessori-based\"). Additionally, phrases like \"arts-integrated charter school\" and \"state-mandated standardized tests\" are common terms used in American schools. Overall, the language and tone of the text seem to align with American English conventions.\n",
      "Conversation List: ['648305a0f230bbb3bf1a2daf', '648305a1a16fd6adf898ebe0']\n",
      "Response: American English\n",
      "\n",
      "error_count: American English\n",
      "punc ['double', 'double', 'double', 'double', 'double', 'double', 'single', 'double', 'double', 'double'] 10\n",
      "Grammer ['Yes', 'Yes', 'Yes', 'Yes', 'Yes.', 'Yes', 'Yes', 'Yes', 'Yes.', 'Yes.'] 10\n",
      "spelling ['American English style.', 'American English style.', 'American English style.', 'American English.', 'American English', '0', 'British English:\\n\\n* For some, this distraction comes in the form of the daily stress that results from poverty, constant uncertainty, and fear, which draws students’ focus away from learning.\\n* For others, it’s the ever-present presence of digital technology in the form of gaming, social media, connection to peers, and constant exposure to the ever-present YouTube and TikTok culture.\\n* Thus, the pandemic has simultaneously compounded the inequalities that already exist between those who have and those who do not access – while at the same time expanding the use of digital technology and increasing our dependence on digital devices and services.\\n* Once we finally get beyond COVID, it is highly unlikely that schools will deny the intrusion of these powerful societal forces and the changes they are imposing upon us because neither factor is well aligned to a compliance-driven solution for education.\\n* As we move forward, education will need to compete for learner attention in a time of ongoing uncertainty and instability on the one hand, and instant access to anytime, anywhere digital entertainment and learning experiences on the other.\\n* Effective classroom management could, in some cases, create environments where at least outwardly, it appeared that students were relatively engaged.\\n* Throughout time, both individually and collectively, educators have exerted influence over learners. But, despite the outward appearance of control manifested and often assumed in the classroom, the reality is that we are all effectively interacting with other individuals and groups who also have agency.\\n* When COVID compelled traditional learning to switch to a remote or hybrid model, the digital prototype used to maintain a semblance of control and order no longer worked as effectively as the in-person model.\\n\\nAmerican English:\\n\\n* For some, this distraction comes in the form of the daily stress that results from poverty, constant uncertainty, and fear, which draws students’ focus away from learning.\\n* For others, it’s the ever-present presence of digital techno', 'American English:\\nThe text appears to be written in American English style. Some key indicators include the spelling of words like \"center\" instead of \"centre,\" and the use of phrases like \"learners have even more reason to turn down the volume and tune us out.\" Overall, the language used is straightforward and easy to understand, which is characteristic of American English.', 'American English:\\n\\nThis text appears to be written in American English. Some key indicators include the use of words like \"Montessoribased,\" which is spelled differently than the British English version (\"Montessori-based\"). Additionally, phrases like \"arts-integrated charter school\" and \"state-mandated standardized tests\" are common terms used in American schools. Overall, the language and tone of the text seem to align with American English conventions.', 'American English'] 10\n",
      "  punctuational error_count grammatical error_count  \\\n",
      "0                    double                     Yes   \n",
      "1                    double                     Yes   \n",
      "2                    double                     Yes   \n",
      "3                    double                     Yes   \n",
      "4                    double                    Yes.   \n",
      "5                    double                     Yes   \n",
      "6                    single                     Yes   \n",
      "7                    double                     Yes   \n",
      "8                    double                    Yes.   \n",
      "9                    double                    Yes.   \n",
      "\n",
      "                                spelling_error_count  \n",
      "0                            American English style.  \n",
      "1                            American English style.  \n",
      "2                            American English style.  \n",
      "3                                  American English.  \n",
      "4                                   American English  \n",
      "5                                                  0  \n",
      "6  British English:\\n\\n* For some, this distracti...  \n",
      "7  American English:\\nThe text appears to be writ...  \n",
      "8  American English:\\n\\nThis text appears to be w...  \n",
      "9                                   American English  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Single_or_double_quotes', 'Series_comma','American_english',\"number_treatment\"])\n",
    "\n",
    "punctuational_error_count, grammatical_error_count, spelling_error_count,missing_articles_count =[],[],[],[]\n",
    "for chunk_data in Modified_chunks[:]:\n",
    "    conversation_list, response = chat_with_bot(chunk_data)\n",
    "    print(\"Conversation List:\", conversation_list)\n",
    "    print(\"Response:\", response)\n",
    "    print()\n",
    "\n",
    "    # Extract the numeric value using regular expressions\n",
    "    # error_count = re.findall(r'\\d+', response.split(\"\\n\")[0])\n",
    "\n",
    "    if error_count:\n",
    "        # Convert the extracted value to an integer\n",
    "        error_count = int(error_count[0])\n",
    "    else:\n",
    "        # If a numeric value is not found, try to convert words to numbers\n",
    "        try:\n",
    "            error_count = response.split(\"\\n\")[0]\n",
    "        except ValueError:\n",
    "            error_count = 0\n",
    "    \n",
    "    print(\"error_count:\", response)\n",
    "\n",
    "    # Determine the column to assign the error count based on the prompt\n",
    "    if \"Single_or_double_quotes\" in chunk_data:\n",
    "        # column_name = 'punctuational error_count'\n",
    "        punctuational_error_count.append(response)\n",
    "    if \"Series_comma\" in chunk_data:\n",
    "        # column_name = 'grammatical error_count'\n",
    "        grammatical_error_count.append(response)\n",
    "    if \"American_english \" in chunk_data:\n",
    "        # column_name = 'spelling_error_count'\n",
    "        spelling_error_count.append(response)\n",
    "    if \"number_treatment\" in chunk_data:\n",
    "        # column_name = 'missing_articles_count'\n",
    "        missing_articles_count.append(error_count)\n",
    "    else:\n",
    "        column_name = None\n",
    "\n",
    "    # print(\"column_name: \", column_name)\n",
    "\n",
    "    # # Add the error count to the dataframe if it is not None and column_name is valid\n",
    "    # if error_count is not None and column_name:\n",
    "    #     if column_name in df.columns:\n",
    "    #         df[column_name] = df.get(column_name, 0) + error_count\n",
    "    #     else:\n",
    "    #         df[column_name] = error_count\n",
    "\n",
    "print(\"punc\",punctuational_error_count,len(punctuational_error_count))\n",
    "print(\"Grammer\",grammatical_error_count,len(grammatical_error_count))\n",
    "print(\"spelling\",spelling_error_count,len(spelling_error_count))\n",
    "# print(\"arti\",missing_articles_count,len(missing_articles_count))\n",
    "df = pd.DataFrame({'punctuational error_count':punctuational_error_count,\n",
    "                   'grammatical error_count':grammatical_error_count, \n",
    "                   'spelling_error_count':spelling_error_count})\n",
    "                #    'missing_articles_count':missing_articles_count})\n",
    "# Print the resulting dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single_or_double_quotes</th>\n",
       "      <th>Series_comma</th>\n",
       "      <th>American_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English style.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English style.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English style.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>American English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>British English:\\n\\n* For some, this distracti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English:\\nThe text appears to be writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>American English:\\n\\nThis text appears to be w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>American English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Single_or_double_quotes Series_comma  \\\n",
       "0                  double          Yes   \n",
       "1                  double          Yes   \n",
       "2                  double          Yes   \n",
       "3                  double          Yes   \n",
       "4                  double         Yes.   \n",
       "5                  double          Yes   \n",
       "6                  single          Yes   \n",
       "7                  double          Yes   \n",
       "8                  double         Yes.   \n",
       "9                  double         Yes.   \n",
       "\n",
       "                                    American_english  \n",
       "0                            American English style.  \n",
       "1                            American English style.  \n",
       "2                            American English style.  \n",
       "3                                  American English.  \n",
       "4                                   American English  \n",
       "5                                                  0  \n",
       "6  British English:\\n\\n* For some, this distracti...  \n",
       "7  American English:\\nThe text appears to be writ...  \n",
       "8  American English:\\n\\nThis text appears to be w...  \n",
       "9                                   American English  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "df.rename(columns={\"punctuational error_count\": \"Single_or_double_quotes\", \"grammatical error_count\": \"Series_comma\",\"American_english\":\"Style\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Single_or_double_quotes</th>\n",
       "      <th>Series_comma</th>\n",
       "      <th>Style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English style.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English style.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English style.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes</td>\n",
       "      <td>American English.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>double</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>American English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Single_or_double_quotes Series_comma                    Style\n",
       "0                  double          Yes  American English style.\n",
       "1                  double          Yes  American English style.\n",
       "2                  double          Yes  American English style.\n",
       "3                  double          Yes        American English.\n",
       "4                  double         Yes.         American English"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
