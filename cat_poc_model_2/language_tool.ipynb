{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 12:37:40.690599: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-27 12:37:40.742825: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 12:37:41.552666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm , trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "import nltk\n",
    "# nltk.download('punkt')  # Download the punkt tokenizer for sentence tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import language_tool_python\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammer_correction(text):\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    # text = 'I am going to Goa.'\n",
    "    matches = tool.check(text)\n",
    "    len(matches)\n",
    "    tool.close() # Call `close()` to shut off the server when you're done.\n",
    "    if len(matches):\n",
    "        return 0\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        resource_manager = PDFResourceManager()\n",
    "        fake_file_handle = io.StringIO()\n",
    "        converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
    "        page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "        \n",
    "        for page in PDFPage.get_pages(file, check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    "            text += fake_file_handle.getvalue()\n",
    "        \n",
    "        converter.close()\n",
    "        fake_file_handle.close()\n",
    "    \n",
    "    return text\n",
    "# Function to divide text into chunks of 512 tokens\n",
    "def divide_text_into_chunks(text, max_chunk_size=512):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for sentence in sentences:\n",
    "        # print(sentence)\n",
    "        # print(\"##########\")\n",
    "        tokenized_sentence = sentence.split()\n",
    "        if len(current_chunk) + len(tokenized_sentence) <= max_chunk_size:\n",
    "            current_chunk += sentence + \" \"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "def divide_text_into_batches(text, batch_size=5):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    num_batches = math.ceil(num_sentences / batch_size)\n",
    "\n",
    "    batches = []\n",
    "    start_idx = 0\n",
    "    for batch_idx in range(num_batches):\n",
    "        end_idx = min(start_idx + batch_size, num_sentences)\n",
    "        batch_sentences = sentences[start_idx:end_idx]\n",
    "        batches.append(\" \".join(batch_sentences))\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_text_local(input_text, language='en-US'):\n",
    "    url = 'http://localhost:8081/v2/check'\n",
    "    params = {'text': input_text, 'language': language}\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['matches']\n",
    "    else:\n",
    "        print(\"Error:\", response.text)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76437\n",
      "33193\n"
     ]
    }
   ],
   "source": [
    "pdf_path = './15031-4983-FullBook.pdf'\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "chunks = divide_text_into_chunks(text)\n",
    "batches = divide_text_into_batches(text, 10)\n",
    "print(len(chunks))\n",
    "print(len(batches))\n",
    "corrected_text = check_text_local(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch Number : 0\n",
      "batch Number : 1\n",
      "batch Number : 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# chunk_label = check_grammar(sentences, GED_model, GED_tokenizer)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m----> 7\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mgrammer_correction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m text:\n\u001b[1;32m      9\u001b[0m         grammer_matches\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m, in \u001b[0;36mgrammer_correction\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrammer_correction\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     tool \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_tool_python\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLanguageTool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men-US\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# text = 'I am going to Goa.'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     matches \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39mcheck(text)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/language_tool_python/server.py:62\u001b[0m, in \u001b[0;36mLanguageTool.__init__\u001b[0;34m(self, language, motherTongue, remote_server, newSpellings, new_spellings_persist, host, config)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_remote_server_config(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url)\n\u001b[1;32m     61\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_server_is_alive():\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start_server_on_free_port()\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m language \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/language_tool_python/server.py:238\u001b[0m, in \u001b[0;36mLanguageTool._start_server_on_free_port\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttp://\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/v2/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_port)\n\u001b[1;32m    237\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start_local_server()\n\u001b[1;32m    239\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mexcept\u001b[39;00m ServerError:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/language_tool_python/server.py:275\u001b[0m, in \u001b[0;36mLanguageTool._start_local_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m match \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_server\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mreadline()\n\u001b[1;32m    276\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[1;32m    277\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grammer_matches = []\n",
    "for idx, chunk in enumerate(batches):\n",
    "    print(\"batch Number :\",idx)\n",
    "    sentences = sent_tokenize(chunk)\n",
    "    # chunk_label = check_grammar(sentences, GED_model, GED_tokenizer)\n",
    "    for i in sentences:\n",
    "        text = grammer_correction(i)\n",
    "        if not text:\n",
    "            grammer_matches.append(i)\n",
    "            grammer_matches.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'languagetool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanguagetool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LanguageTool\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_text_local\u001b[39m(input_text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-US\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      4\u001b[0m     tool \u001b[38;5;241m=\u001b[39m LanguageTool(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:8081\u001b[39m\u001b[38;5;124m'\u001b[39m, language)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'languagetool'"
     ]
    }
   ],
   "source": [
    "from languagetool import LanguageTool\n",
    "\n",
    "def check_text_local(input_text, language='en-US'):\n",
    "    tool = LanguageTool('http://localhost:8081', language)\n",
    "    errors = tool.check(input_text)\n",
    "    return errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_to_check = \"Learner Voice, Learner Choice offers fresh, forward-thinking\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_to_check = \"Learner Voice, Learner Choice offers fresh, forward-thinking supports for teachers creating an empowered, student-centered classroom.\"\n",
    "    errors = check_text_local(text_to_check)\n",
    "    print(\"Number of errors:\", len(errors))\n",
    "    for error in errors:\n",
    "        print(f\"{error['rule']['id']}: {error['message']} (Line: {error['context']['offset']}, Column: {error['context']['offset']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
